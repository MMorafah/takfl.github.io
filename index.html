<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="TAKFL">
  <meta property="og:title" content="TAKFL"/>
  <meta property="og:description" content="Towards Diverse Device Heterogeneous Federated Learning via Task Arithmetic Knowledge Integration"/>
  <meta property="og:url" content="https://mmorafah.github.io/takflpage/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/figure_main.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>TAKFL</title>
  <link rel="icon" type="image/x-icon" href="static/images/figure_main.jpg">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- NeurIPS logo next to the title -->
            <h1 class="title is-1 publication-title">Towards Diverse Device Heterogeneous Federated Learning via Task Arithmetic Knowledge Integration</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href=https://mmorafah.github.io/homepage/ target="_blank">Mahdi Morafah</a><sup>1*</sup>,</span>
                <span class="author-block">
                  Vyacheslav Kungurtsev<sup>2</sup>,</span>
                  <span class="author-block">
                    Hojin Chang<sup>1</sup>,
                  </span>
                  <span class="author-block">
                    <a href=https://www.crcv.ucf.edu/chenchen/ target="_blank">Chen Chen</a><sup>3</sup>,
                  </span>
                  <span class="author-block">
                    Bill Lin<sup>1</sup>,
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                      <span class="author-block">
                          <sup>1</sup>University of California San Diego (UCSD), 
                          <sup>2</sup>Czech Technical University in Prague<br>
                          <sup>3</sup>University of Central Florida (UCF)
                      </span>
                      <span class="eql-cntrb">
                          <br><sup>*</sup>Correspondence: 
                          <a href="mailto:mmorafah@ucsd.edu">mmorafah@ucsd.edu</a>
                      </span>
                      <!-- Add icons here -->
                      <div class="icons-row">
                        <img src="static/images/ucsd.png" alt="UCSD Logo" class="icon-logo" style="width: 80px; height: 80px;">
                        <img src="static/images/cezch.jpg" alt="CZECH Logo" class="icon-logo" style="width: 100px; height: 80px;">
                        <img src="static/images/ucf.jpg" alt="UCF Logo" class="icon-logo" style="width: 120px; height: 80px;">
                      </div>
                      <br>
                      <!-- Container for the centered NeurIPS logo and text -->
                      <div style="display: flex; align-items: center; justify-content: center; margin-top: -20px; margin-bottom: -10px;">
                        <span class="highlight-neurips" style="display: inline-flex; align-items: center; text-align: center;">
                          <span style="font-size: 26px; margin-right: 10px;">NeurIPS 2024</span>
                          <img src="static/images/neurips.png" alt="NeurIPS Logo" class="neurips-logo" style="width: 110px; height: auto;">
                        </span>
                      </div>
                  </div>


                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/MMorafah/TAKFL" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Federated Learning (FL) has emerged as a promising paradigm for collaborative machine learning, while preserving user data privacy. Despite its potential, standard FL algorithms lack support for diverse heterogeneous device prototypes, which vary significantly in model and dataset sizes---from small IoT devices to large workstations. 
    This limitation is only partially addressed by existing knowledge distillation (KD) techniques, which often fail to transfer knowledge effectively across a broad spectrum of device prototypes with varied capabilities. This failure primarily stems from two issues: the dilution of informative logits from more capable devices by those from less capable ones, and the use of a single integrated logits as the distillation target across all devices, which neglects their individual learning capacities and and the unique contributions of each device.
    To address these challenges, we introduce <b>TAKFL</b>, a novel KD-based framework that treats the knowledge transfer from each device prototype's ensemble as a separate task, independently distilling each to preserve its unique contributions and avoid dilution. <b>TAKFL</b> also incorporates a KD-based self-regularization technique to mitigate the issues related to the noisy and unsupervised ensemble distillation process. 
    To integrate the separately distilled knowledge, we introduce an adaptive <em>task arithmetic</em> knowledge integration process, allowing each student model to customize the knowledge integration for optimal performance. Additionally, we present theoretical results demonstrating the effectiveness of task arithmetic in transferring knowledge across heterogeneous device prototypes with varying capacities.
    Comprehensive evaluations of our method across both computer vision (CV) and natural language processing (NLP) tasks demonstrate that <b>TAKFL</b> achieves state-of-the-art results in a variety of datasets and settings, significantly outperforming existing KD-based methods.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Device Heterogeneous FL Section -->
<section class="overview-section" style="padding: 10px 0; background-color: #f0f4f8;"> <!-- Light background color applied here -->
  <div class="container has-text-centered">
    <!-- Title -->
    <h1 class="title overview-title" style="color: #333;">Device Heterogeneous FL</h1>

    <!-- Teaser Image -->
    <div class="teaser-image">
      <img src="static/images/problem.jpg" alt="Overview Image" style="max-width: 80%; height: auto; border-radius: 8px; border: 1px solid #ddd; margin-bottom: 10px;">
    </div>

    <!-- Image Caption/Explanation -->
    <p class="teaser-caption" style="font-size: 1em; color: #2c3e50; line-height: 1.5; background-color: #ecf0f1; padding: 10px; border-radius: 8px; border: 1px solid #bdc3c7; text-align: left; margin: 0 auto; max-width: 100%; margin-top: 10px;">
      In practice, there is a wide range of device prototypes, from small devices such as IoT devices, and medium-sized ones like smartphones, 
      to large-scale systems like workstations. Each of these devices has unique, unhashable neural network architectures designed to 
      fit their specific hardware, software configurations, and machine learning tasks. The capabilities of these devices vary significantly,
      with smaller devices (e.g., IoT) having smaller models and smaller datasets, while larger devices (e.g., workstations) 
      have larger models and larger datasets.
      Additionally, these methods employ this single integrated distillation target to transfer knowledge across all different-size student models.
      These diverse device prototypes with heterogeneous model architectures participate in FL to enhance their global model performance through mutual knowledge sharing.
      In this figure, we have depicted a scenario of three different devices prototypes including IoTs, smartphones, and workstations.
    </p>
  </div>
</section>
<!-- End of Device Heterogeneous FL Section -->


<!-- Limitations of KD-based Device Heterogeneous FL Section -->
<section class="overview-section">
  <div class="container has-text-centered">
    <!-- Title -->
    <h1 class="title overview-title">Limitations of KD-based Device Heterogeneous FL</h1>

    <!-- Teaser Image -->
    <div class="teaser-image">
      <img src="static/images/figure_avgkd.jpg" alt="Overview Image" style="max-width: 50%; height: auto; border-radius: 8px; border: 1px solid #ddd; margin-bottom: 10px;">
    </div>

    <!-- Image Caption/Explanation -->
    <p class="teaser-caption" style="font-size: 1em; color: #2c3e50; line-height: 1.5; background-color: #ecf0f1; padding: 10px; border-radius: 8px; border: 1px solid #bdc3c7; text-align: left; margin: 0 auto; max-width: 100%; margin-top: 10px;">
      <strong>Knowledge distillation (KD)</strong> in device-heterogeneous FL facilitates knowledge transfer by using locally updated client models from different device prototypes—collectively termed as <em>ensembles</em>—as teachers to distill their knowledge into each device prototype's server student model, using an unlabeled public dataset.
      While existing works primarily focus on same-size devices with similar capabilities, they often overlook the significant variation in device prototypes, ranging from small IoT devices to large workstations.
      As shown in this figure, different-sized ensembles' logits are being averaged and used as the target distillation to transfer knowledge to each server-side student model.
      Unfortunately, existing methods struggle to establish effective knowledge transfer in these challenging, real-world device-heterogeneous settings, primarily due to two reasons: <br>
      <span style="display: inline-block; background-color: #f9f7d9; color: black; padding: 3px 8px; border-radius: 50%; border: 1px solid black; font-weight: bold; font-size: 16px;">1</span> Existing methods often disregard the individual strengths and information quality of each device prototype's ensembles and integrate their logits into a single distillation target. This approach dilutes the richer, more informative logits from larger, more capable devices with less informative logits from smaller, less capable ones. <br>
      <span style="display: inline-block; background-color: #f9f7d9; color: black; padding: 3px 8px; border-radius: 50%; border: 1px solid black; font-weight: bold; font-size: 16px;">1</span> Additionally, these methods employ this single integrated distillation target to transfer knowledge across all different-size student models. This one-size-fits-all approach fails to provide customized knowledge integration based on the unique learning capacities of each student and the specific helpfulness of each device prototype’s ensembles.

</section>
<!-- End of Device Heterogeneous FL Section -->

<!-- Overview Section with Image Carousel -->
<section class="overview-section">
  <div class="container has-text-centered">
    <!-- Title -->
    <h1 class="title overview-title">Overview</h1>

    <!-- Image Carousel -->
    <div id="results-carousel" class="carousel results-carousel" style="overflow: hidden; width: 100%;" data-interval="false"> <!-- Disabling auto-slide -->

      <!-- First Image -->
      <div class="item" style="position: relative; width: 100%;">
        <div class="teaser-image">
          <img src="static/images/figure_main.jpg" alt="Overview Image 1" style="max-width: 100%; height: auto; border-radius: 8px; border: 1px solid #ddd; margin-bottom: 10px;">
        </div>
        <!-- Caption -->
        <div class="caption-container" style="text-align: left; padding: 10px; background-color: #f8f8f8; border: 1px solid #ccc; border-radius: 8px; margin-top: 10px; width: 100%;">
          <p class="teaser-caption" style="font-size: 1em; color: #2c3e50 !important; line-height: 1.5;">
            This image showcases the key steps in our process: reconstruction, recognition, and registration. 
            The pipeline starts with the query image, followed by extracting sparse keypoints, recognizing landmarks, 
            and registering them in a 3D space.
          </p>
        </div>
      </div>
      
      <!-- Second Image -->
      <div class="item" style="position: relative; width: 100%;">
        <div class="teaser-image">
          <img src="static/images/fl_task_vector.jpg" alt="Overview Image 2" style="max-width: 100%; height: auto; border-radius: 8px; border: 1px solid #ddd; margin-bottom: 10px;">
        </div>
        <!-- Caption -->
        <div class="caption-container" style="text-align: left; padding: 10px; background-color: #f8f8f8; border: 1px solid #ccc; border-radius: 8px; margin-top: 10px; width: 100%;">
          <p class="teaser-caption" style="font-size: 1em; color: #2c3e50 !important; line-height: 1.5;">
            This second image depicts a detailed FL task vector that highlights various stages of federated learning, 
            from task formulation to optimization.
          </p>
        </div>
      </div>

    </div>
  </div>
</section>
<!-- End of Overview Section with Image Carousel -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/carousel1.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          First image description.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/carousel2.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Second image description.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/carousel3.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Third image description.
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/carousel4.jpg" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Fourth image description.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->



<!-- Youtube video -->
<!--
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
-->
<!-- End youtube video -->
<!-- Paper poster -->
<!--
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->
-->

<!-- Acknowledgement -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Acknowledgement</h2>
        <div class="content has-text-justified">
          <p>
            This research was partially supported by a grant from Cisco Systems, Inc. We also gratefully acknowledge the use of the computational infrastructure provided by the OP VVV funded project CZ.02.1.01/0.0/0.0/16\_019/0000765, “Research Center for Informatics,” which enabled us to conduct the experiments presented in this work.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Acknowledgement -->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>, which is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
